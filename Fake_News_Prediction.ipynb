{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake News Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYGYNrZ6Kz0QVMxI0iS1Oh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PraveenSingh-ML-0728/Classification_Problems/blob/main/Fake_News_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vntg8Pl_556g"
      },
      "source": [
        "#while True:pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG0M8WxYlXOl"
      },
      "source": [
        "Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmB0wQUMlBIC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re     #RegularExpression:-For searching a text in a Documents ...\n",
        "from nltk.corpus import stopwords   #NaturalLanguageToolKit(stopwords: the that a an or we say article...)\n",
        "from nltk.stem.porter import PorterStemmer  #Stemming is the process of reducing a word to its Root Word ... Example :- actor, actress, acting ---> act\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer   #TfidfVectorizer is for converting the text into features vector...\n",
        "from sklearn.model_selection import train_test_split    #Use to split our Data into training and Test Data ...\n",
        "from sklearn.linear_model import LogisticRegression     #Select the LogisticRegression Model ...\n",
        "from sklearn.metrics import accuracy_score    #To find the Accuracy of the Model ..."
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5hrf_HEoGLN",
        "outputId": "9b2d6097-20ab-472c-e994-fdaa2e8283c5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkYIfZXAoRUu",
        "outputId": "b901741b-2df4-4a78-c90d-4e0fa71ed135"
      },
      "source": [
        "#Printing the stop words in English\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqdtSEato0Ej"
      },
      "source": [
        "Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsbrfdomzEh4"
      },
      "source": [
        "news_dataset =pd.read_csv('/content/train.csv')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAj-9l49rlCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97f4fcb-405a-4036-f937-9c58478279a7"
      },
      "source": [
        "news_dataset.shape  #20800 Articles and 5 Features"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20800, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULJwiWYgrrUr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "1a4f420a-afc8-4940-ee79-a893930837b5"
      },
      "source": [
        "news_dataset.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "1   1  ...     0\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJf7D9Hq6hcH",
        "outputId": "3df8d360-d106-45f2-d69c-912bd141d2f2"
      },
      "source": [
        "#Counting the number of missing values in datasets\n",
        "news_dataset.isnull().sum() #There are 558 missing value in title column in text 39 are missing etc ..."
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id           0\n",
              "title      558\n",
              "author    1957\n",
              "text        39\n",
              "label        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdTps9I464VY"
      },
      "source": [
        "#Replacing the null values by string\n",
        "news_dataset = news_dataset.fillna('')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UwpG2358JyX",
        "outputId": "3ca97a89-7136-418e-a777-7a820a97562c"
      },
      "source": [
        "news_dataset.isnull().sum()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "title     0\n",
              "author    0\n",
              "text      0\n",
              "label     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cToGcb1q8Mc9"
      },
      "source": [
        "# Now merging the title and Author name as because its seem a important feature here ...\n",
        "news_dataset['content'] = news_dataset['author']+' '+news_dataset['title']"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1voDLr79G5t",
        "outputId": "534e0a37-32b6-40fd-a459-619715a904ea"
      },
      "source": [
        "print(news_dataset['content'])  #Here we can use the new content column for Prediction"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        Darrell Lucus House Dem Aide: We Didn’t Even S...\n",
            "1        Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
            "2        Consortiumnews.com Why the Truth Might Get You...\n",
            "3        Jessica Purkiss 15 Civilians Killed In Single ...\n",
            "4        Howard Portnoy Iranian woman jailed for fictio...\n",
            "                               ...                        \n",
            "20795    Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...\n",
            "20796    Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...\n",
            "20797    Michael J. de la Merced and Rachel Abrams Macy...\n",
            "20798    Alex Ansary NATO, Russia To Hold Parallel Exer...\n",
            "20799              David Swanson What Keeps the F-35 Alive\n",
            "Name: content, Length: 20800, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3J0SzFo9Q9o"
      },
      "source": [
        "# Now Separating the Data and Labels\n",
        "X = news_dataset.drop(columns='label', axis=1)\n",
        "Y = news_dataset['label']"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip7D7cvJ-O3Q",
        "outputId": "07ea5477-01c9-4373-bd82-36584b3c8abf"
      },
      "source": [
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          id  ...                                            content\n",
            "0          0  ...  Darrell Lucus House Dem Aide: We Didn’t Even S...\n",
            "1          1  ...  Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
            "2          2  ...  Consortiumnews.com Why the Truth Might Get You...\n",
            "3          3  ...  Jessica Purkiss 15 Civilians Killed In Single ...\n",
            "4          4  ...  Howard Portnoy Iranian woman jailed for fictio...\n",
            "...      ...  ...                                                ...\n",
            "20795  20795  ...  Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...\n",
            "20796  20796  ...  Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...\n",
            "20797  20797  ...  Michael J. de la Merced and Rachel Abrams Macy...\n",
            "20798  20798  ...  Alex Ansary NATO, Russia To Hold Parallel Exer...\n",
            "20799  20799  ...            David Swanson What Keeps the F-35 Alive\n",
            "\n",
            "[20800 rows x 5 columns]\n",
            "0        1\n",
            "1        0\n",
            "2        1\n",
            "3        1\n",
            "4        1\n",
            "        ..\n",
            "20795    0\n",
            "20796    0\n",
            "20797    0\n",
            "20798    1\n",
            "20799    1\n",
            "Name: label, Length: 20800, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1sS3dYZ-sju"
      },
      "source": [
        "Stemming:\n",
        "\n",
        "Stemming is the process of reducing a word to its Root Word ...\n",
        "Example :- actor, actress, acting ---> act"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjGmgngd-TsM"
      },
      "source": [
        "port_stem = PorterStemmer()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAqSFoAN_mD3"
      },
      "source": [
        "def stemming(content):\n",
        "  stemmed_content = re.sub('[^a-zA-Z]',' ',content) #remove all the numbers and puncuation in a content ...and the numbers and puncuation are replaced by a space ...\n",
        "  stemmed_content = stemmed_content.lower() #convert all the letters to lowercase ...\n",
        "  stemmed_content = stemmed_content.split() #All words get splitted and converted to a list ...\n",
        "  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] # This means in my content I would take all the words which are not a stopwords ...\n",
        "  stemmed_content = ' '.join(stemmed_content) #Now Joining all the words having space in Between ...\n",
        "  return stemmed_content  #Then return with our Processed Text as we get the text having No numbers puncuations etc ..."
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fk0et_EBpah"
      },
      "source": [
        "news_dataset['content'] = news_dataset['content'].apply(stemming)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7IEGiVNE6I9",
        "outputId": "ee6a7abb-734a-483e-e4d9-d242d4ad12c8"
      },
      "source": [
        "print(news_dataset['content'])  #Here we are getting all word in Lowercase  and no numbers and puncuation ..."
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        darrel lucu hous dem aid even see comey letter...\n",
            "1        daniel j flynn flynn hillari clinton big woman...\n",
            "2                   consortiumnew com truth might get fire\n",
            "3        jessica purkiss civilian kill singl us airstri...\n",
            "4        howard portnoy iranian woman jail fiction unpu...\n",
            "                               ...                        \n",
            "20795    jerom hudson rapper trump poster child white s...\n",
            "20796    benjamin hoffman n f l playoff schedul matchup...\n",
            "20797    michael j de la merc rachel abram maci said re...\n",
            "20798    alex ansari nato russia hold parallel exercis ...\n",
            "20799                            david swanson keep f aliv\n",
            "Name: content, Length: 20800, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCDuxXXdFPwJ"
      },
      "source": [
        "#Separating the Data and Label\n",
        "X = news_dataset['content'].values\n",
        "Y = news_dataset['label'].values"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-5QNT27GPEl",
        "outputId": "587c3322-c8d6-4c29-935b-6a8ea8eba56c"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['darrel lucu hous dem aid even see comey letter jason chaffetz tweet'\n",
            " 'daniel j flynn flynn hillari clinton big woman campu breitbart'\n",
            " 'consortiumnew com truth might get fire' ...\n",
            " 'michael j de la merc rachel abram maci said receiv takeov approach hudson bay new york time'\n",
            " 'alex ansari nato russia hold parallel exercis balkan'\n",
            " 'david swanson keep f aliv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21Tj95WRGSEl",
        "outputId": "3b70f79d-fdd3-4aa7-ec34-78eebd20f891"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAiE4NR2Ggju",
        "outputId": "2d41277f-f878-4315-ccfc-e30d94464542"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20800,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KkDTdkNGscM"
      },
      "source": [
        "# Converting the textual data to numerical Data\n",
        "vectorizer = TfidfVectorizer()  #TermfrequencyInverseDocumentFrequency:- counts the no.of times a particular word is repeating in a paragraph or text so it is very important as because it always repeats so it assign a numeric value to that repeated word ...\n",
        "vectorizer.fit(X)\n",
        "\n",
        "X = vectorizer.transform(X)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP4W-2YmI2lT",
        "outputId": "ddfc0706-36af-415e-b3b9-ffd1f5e6661c"
      },
      "source": [
        "print(X)  # Now it converted to Numeric value by TfidfVectorizer as because our machine learning Model \n",
        "# can't understand the textual data or string so that's why we transform the text to numeric values for good understanding for our ML Model ..."
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 15686)\t0.28485063562728646\n",
            "  (0, 13473)\t0.2565896679337957\n",
            "  (0, 8909)\t0.3635963806326075\n",
            "  (0, 8630)\t0.29212514087043684\n",
            "  (0, 7692)\t0.24785219520671603\n",
            "  (0, 7005)\t0.21874169089359144\n",
            "  (0, 4973)\t0.233316966909351\n",
            "  (0, 3792)\t0.2705332480845492\n",
            "  (0, 3600)\t0.3598939188262559\n",
            "  (0, 2959)\t0.2468450128533713\n",
            "  (0, 2483)\t0.3676519686797209\n",
            "  (0, 267)\t0.27010124977708766\n",
            "  (1, 16799)\t0.30071745655510157\n",
            "  (1, 6816)\t0.1904660198296849\n",
            "  (1, 5503)\t0.7143299355715573\n",
            "  (1, 3568)\t0.26373768806048464\n",
            "  (1, 2813)\t0.19094574062359204\n",
            "  (1, 2223)\t0.3827320386859759\n",
            "  (1, 1894)\t0.15521974226349364\n",
            "  (1, 1497)\t0.2939891562094648\n",
            "  (2, 15611)\t0.41544962664721613\n",
            "  (2, 9620)\t0.49351492943649944\n",
            "  (2, 5968)\t0.3474613386728292\n",
            "  (2, 5389)\t0.3866530551182615\n",
            "  (2, 3103)\t0.46097489583229645\n",
            "  :\t:\n",
            "  (20797, 13122)\t0.2482526352197606\n",
            "  (20797, 12344)\t0.27263457663336677\n",
            "  (20797, 12138)\t0.24778257724396507\n",
            "  (20797, 10306)\t0.08038079000566466\n",
            "  (20797, 9588)\t0.174553480255222\n",
            "  (20797, 9518)\t0.2954204003420313\n",
            "  (20797, 8988)\t0.36160868928090795\n",
            "  (20797, 8364)\t0.22322585870464118\n",
            "  (20797, 7042)\t0.21799048897828688\n",
            "  (20797, 3643)\t0.21155500613623743\n",
            "  (20797, 1287)\t0.33538056804139865\n",
            "  (20797, 699)\t0.30685846079762347\n",
            "  (20797, 43)\t0.29710241860700626\n",
            "  (20798, 13046)\t0.22363267488270608\n",
            "  (20798, 11052)\t0.4460515589182236\n",
            "  (20798, 10177)\t0.3192496370187028\n",
            "  (20798, 6889)\t0.32496285694299426\n",
            "  (20798, 5032)\t0.4083701450239529\n",
            "  (20798, 1125)\t0.4460515589182236\n",
            "  (20798, 588)\t0.3112141524638974\n",
            "  (20798, 350)\t0.28446937819072576\n",
            "  (20799, 14852)\t0.5677577267055112\n",
            "  (20799, 8036)\t0.45983893273780013\n",
            "  (20799, 3623)\t0.37927626273066584\n",
            "  (20799, 377)\t0.5677577267055112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovj53phFJsxc"
      },
      "source": [
        "Splitting our Dataset to Training & Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcGRIFNXI5tf"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size =0.2, stratify=Y, random_state=2)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCXKiIGDK6Mz"
      },
      "source": [
        "Training The Model: LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJY707V2Kz1c"
      },
      "source": [
        "model = LogisticRegression()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO4YQ035Lslw",
        "outputId": "aab94553-f7c3-43eb-ce91-9d843ae92279"
      },
      "source": [
        "model.fit(X_train, Y_train) #Trained our Model ..."
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpXWpvzDMBx7"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLQ5_AESMFep"
      },
      "source": [
        "Now will find the Accuracy value/Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1tFXJD4L57C"
      },
      "source": [
        "#Accuracy score on the training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train) #Y_train is the original label and \n",
        "                                                                      #X_train_prediction is predicted by our trained model ..."
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdP_rOf_NQfz",
        "outputId": "5a04e7bf-d014-45e6-ba21-bc9cc9b41bbe"
      },
      "source": [
        "print('Accuracy Score Of The Training Data : ',training_data_accuracy)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score Of The Training Data :  0.9865985576923076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbv0vwjlNjPs"
      },
      "source": [
        "#Accuracy score on the test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "testing_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0415mlRpOCpX",
        "outputId": "2c3a0401-4c4a-4644-bdb0-ccc973e7674e"
      },
      "source": [
        "print('Accuracy Score Of The Testing Data : ',testing_data_accuracy)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score Of The Testing Data :  0.9790865384615385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAluSgcOOWBe"
      },
      "source": [
        "Making A Predictive System ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyJWx0hsOIhD",
        "outputId": "9fde4090-e62f-4098-f2c0-bf668b464cde"
      },
      "source": [
        "X_new = X_test[1000] # 0,1,2 ... means the first/second/thire ... row in our X_test column ...\n",
        "\n",
        "prediction = model.predict(X_new)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0]==0):\n",
        "  print(\"The news is Real ...\")\n",
        "else:\n",
        "  print(\"The news is Fake ...\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "The news is Real ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0lpixt3PK5o",
        "outputId": "f4272709-2a06-4946-d0d4-a3ed8ca1faf2"
      },
      "source": [
        "#For testing our model is predicting correct or not we can test it with our Y_test data...\n",
        "print(Y_test[1000])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trPdk98P3WB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}